# Amazon S3 (Simple Storage Service)

Amazon S3 is AWS's scalable object storage used to store any volume of data for backup, archival, big data, or application assets.

---

## Core Concepts

| Term       | Description                                                                |
| ---------- | -------------------------------------------------------------------------- |
| **Bucket** | A globally unique container for storing objects.                           |
| **Object** | The actual file/data stored in S3 with its metadata and key.               |
| **Key**    | Unique identifier for an object within a bucket (like a file path).        |
| **Prefix** | Logical grouping of keys (used for pseudo-folder structures).              |
| **Region** | Specifies where data is stored physically; impacts latency and compliance. |

---

## Why Use S3?

* Store unlimited objects (up to 5 TB per object)
* Pay only for what you use (no minimum storage)
* Seamless integration with AWS services (Athena, Glue, EMR, etc)
* Ideal for static website hosting, backup, analytics, ML input data

---

## Storage Classes Summary

| Class                | Retrieval Time | Ideal For                                                  |
| -------------------- | -------------- | ---------------------------------------------------------- |
| Standard             | Instant        | Frequent access (e.g., websites, active pipelines)         |
| Intelligent-Tiering  | Instant        | Unpredictable access without manual cost optimization      |
| Standard-IA          | Milliseconds   | Infrequent access but must be instantly retrievable        |
| One Zone-IA          | Milliseconds   | Infrequent access; acceptable to lose data in one AZ       |
| Glacier Instant      | Milliseconds   | Archival data with fast access needed occasionally         |
| Glacier Flexible     | Minutes–hours  | Archival data with very rare access                        |
| Glacier Deep Archive | 12–48 hours    | Long-term backups (regulatory compliance, rarely accessed) |

---

## Example Use Cases

* **Standard**: Raw logs, active dashboards, machine learning training data
* **Intelligent-Tiering**: IoT sensor data or unknown access patterns
* **Standard-IA**: Monthly reports or backups
* **Glacier / Deep Archive**: Legal archives, compliance records

---

## Sample S3 Bucket Policy (Full Access)

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": "s3:*",
      "Resource": [
        "arn:aws:s3:::your-bucket-name",
        "arn:aws:s3:::your-bucket-name/*"
      ]
    }
  ]
}
```

---

## Why Durability Matters

Durability measures how reliably your data will survive over time.

Amazon S3 provides **11 nines of durability (99.999999999%)**, which means that if you store **10 billion objects**, you might statistically lose **just one object every 10,000 years** due to internal issues.

This high durability is achieved through:

* **Automatic replication across multiple Availability Zones (AZs)**
* **Continuous checksumming to detect and repair corruption**
* **Optional versioning and replication for added protection**

Even if an entire AZ fails, your data remains safe and accessible from others.

> **Durability ≠ Availability**: Durability protects long-term data integrity. Availability ensures your data is reachable at any moment.

---

## Integration Highlights

* **Athena**: Query S3 data using SQL.
* **Glue**: Crawlers and ETL jobs on S3.
* **Redshift Spectrum**: Query S3 external tables from Redshift.
* **Lambda**: Trigger functions on S3 events (uploads, deletes).
